{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVR7NOQBRJg0"
   },
   "source": [
    "# 분류의 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDVRaITFo1e6"
   },
   "source": [
    "필요한 패키지와 라이브러리 설치하고 사용할 함수를 먼저 정의한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMpOII92RGPW",
    "outputId": "91810e3a-9b30-4227-eb0e-7e8e5e35ce0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:\n",
      "sudo: a password is required\n",
      "Password:"
     ]
    }
   ],
   "source": [
    "# 한글 폰트가 깨질 때 사용 - 런타임 메뉴에서 다시 시작 및 모두 실행 선택. (출처: https://teddylee777.github.io/colab/colab-korean)\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPt9TXh8bxZx",
    "outputId": "f31d3f75-bc38-4ed1-e1a8-cf2dd89d3bcf"
   },
   "outputs": [],
   "source": [
    "# pandas 라이브러리의 탐색적 데이터 분석 도구(explanatory data analysis tool, profiling)를 설치한다.\n",
    "!pip install -U pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ton6J8vKRNz3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSaXL4u_ReC_"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', family='NanumBarunGothic') # clolab 에서 한글 사용 \n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)   # 그림 크기 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrapFoQJbMR9"
   },
   "outputs": [],
   "source": [
    "#기계학습 모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 기계학습 평가 도구\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-suxIl02MeoJ"
   },
   "outputs": [],
   "source": [
    "# 표준화 함수\n",
    "def standarize(x):\n",
    "  return (x - np.mean(x))/np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eV6OTwVmYr1"
   },
   "source": [
    "## 분류의 평가 기준 \n",
    "\n",
    "앞 절에서 이항 변수(binary variable)을 예측하는 분류 방법들을 알아보았다.\n",
    "\n",
    "분류에 사용된 기계학습 모형이 얼마나 분류를 잘 수행하였는지 평가하는 기준이 있어야 서로 다른 방법들을 비교할 수 있다. \n",
    "\n",
    "학습데이터에 포함된 반응변수의 값 $y$ 과 적합된 모형을로 부터 에측된 값 $\\hat y$ 을 비교하여 일치하는 비율을 **예측의 정확성(prediction accuracy)** 이라고 하며 예측모형을 평가하는 가장 기본적인 측조이다.\n",
    "\n",
    "$$ \\text{Accuracy } = \\frac{\\text{ number of records for which } y_i = \\hat y_i}{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBIPBXw-xZ8n"
   },
   "source": [
    "## 학습 데이터와 평가 데이터\n",
    "\n",
    "\n",
    "예측의 정확성을 계산할 때 주의할 점은 모형의 적합에 사용된 데이터와 평가를 수행하는 데이터가 일치하면 모형의 실제 정확성을 과대 추정할 수 있는 위험성이 있다는 것이다.\n",
    "\n",
    "우리가 자신에 대한 평가를 하는 경우를 생삿해 보자. 내가 나 자신을  평가하면  다른 사람들이 나를 평가하는 것보다 더 좋은 평가를 내릴 위험성이 크다는 의미이다. \n",
    "\n",
    "따라서 모형의 공정하고 정확한 평가를 수행하기 위해서는 사용할 수 잇는 데이터를 다음과 같이 두 개로 나누어야 한다.\n",
    "\n",
    "- **학습 데이터(training data)** : 모형을 적합하고 계수를 추정하는데 사용되는 데이터\n",
    "- **검증 데이터(test data, validation data)** : 모형의 예측 능력을 평가하는 데이터\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQEakUvQ0ub1"
   },
   "source": [
    "![학습데이터, 검증데이터](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X81-PV7f1Pim"
   },
   "source": [
    "## 심장병 데이터\n",
    "\n",
    "심혈관 질환(Cardiovascular disease)은 전 세계 사망 원인 1위이며 매년 약 1,790만 명이 사망하며 이는 전 세계 사망의 31%를 차지한다. 심혈관 질환으로 인한 사망 5건 중 4건은 심장마비와 뇌졸중으로 인한 것이며, 이 중 3분의 1은 70세 미만에서 조기에 발생한다. \n",
    "\n",
    "이 절에서 이용할 자료는 [Kaggle](https://www.kaggle.com/fedesoriano/heart-failure-prediction?select=heart.csv)\n",
    " 에서 얻을 수 있는 공공 데이터 세트이며 심장 질환을 예측하는 데 사용할 수 있는 11가지 변수가 포함된 자료이다.\n",
    "\n",
    "자료를 다운로드 하여 데이터프레임 `heart` 에 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7TfBwb0aWmV"
   },
   "outputs": [],
   "source": [
    "url = \"https://ilovedata.github.io/teaching/bigdata2/data/heart.csv\"\n",
    "heart = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-tn9O7qcuEV"
   },
   "outputs": [],
   "source": [
    "heart['FastingBS'] = heart['FastingBS'].astype(int)\n",
    "heart['HeartDisease'] = heart['HeartDisease'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WaxjIvD72-Ai",
    "outputId": "5c01d22d-c84f-4781-9d9f-2101d4b4a5cf"
   },
   "outputs": [],
   "source": [
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "19bQCOvMaffE",
    "outputId": "219a5a1a-102c-472d-c492-4fa73dfd55e6"
   },
   "outputs": [],
   "source": [
    "heart.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxA8qXT_eLAZ"
   },
   "source": [
    "데이터프레임 `heart` 의 각 열에 대한 설명은 다음과 같다. 마지막 변수 `HeartDisease` 가 반응변수이며 나머지는 모두 설명변수이다.\n",
    "\n",
    "| Feature | Description |\n",
    "| :- | :- |\n",
    "| Age | 연령 (연) |\n",
    "| Sex | 성별 (M: 남성, F: 여성) |\n",
    "| ChestPainType | 가슴의 통증 분류 [TA: 전형적인 협심증 통증(Typical Angina), ATA: 비전형적 협심증(Atypical Angina, NAP: 비협심증 통증(Non-Anginal Pain), ASY: 없음) |\n",
    "| RestingBP | 혈압 (mm Hg) |\n",
    "| Cholesterol | 콜레스테롤 (mm/dl) |\n",
    "| FastingBS | 공복혈당 (1: 만약 공복혈당 > 120 mg/dl, 0: 아니면) |\n",
    "| RestingECG | 심전도 결과 (Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria) |\n",
    "| MaxHR | 최대 심박수 (60 과 202 사이의 숫자) |\n",
    "| ExerciseAngina | 운동 유발성 협심증 (Y: 예, N: 아니오) |\n",
    "| Oldpeak | oldpeak = ST (Numeric value measured in depression) |\n",
    "| ST_Slope | the slope of the peak exercise ST segment (Up: upslo ping, Flat: flat, Down: downsloping) |\n",
    "| HeartDisease | 결과 (1: 심장병 있음, 0: 심장병 없음) |\n",
    "\n",
    "\n",
    "각 변수에 대한 분포를 구하고 기초 통계량과 상관관계를 살펴 보자. 데이터에 대한 탐색적 분석을 위하여 `pandas` 라이브러리에서 제공하는 `profile_report()` 메소드를 사용해보자. `profile_report()`는 여러 가지 다양한 통계량을 일목요연하게 HTML 형식으로 나타내어 준다. `profile_report()` 를 이용하려면 터미널에서 다음과 같이 패키지를 설치해야 한다. \n",
    "\n",
    "```\n",
    "pip install -U pandas-profiling\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917,
     "referenced_widgets": [
      "270236bb31694fe3a7628d5a3d238662",
      "fb32ead6fcc344ce9e3164526025722f",
      "1530650cb0e742bc848469728590d9ed",
      "82399b21b2144de48794c05faccad776",
      "310123d0106e4e42a277b0c35697362f",
      "363956fd0d824ca7b90fdc62accded8c",
      "a181b24b240a4366a67e816c80b9500c",
      "f6ae3e813489475bbcb07c19d64dc79b",
      "4bc14ae0a4724f27a587a256c9614f35",
      "b592456c1c2e40d9a50c9e9241d514c5",
      "6283a7e4889844e3bbce8812b7ffce46",
      "19d7515bf7b3414786f4442a07ab7c17",
      "e925c8a999974f889197ed124c089c12",
      "65d33783d85548409b2fbc5eb99a1745",
      "02d6263e85ca45569c7f8619eedf2043",
      "c17dd25ab54b479fbb8abcd506f3de86",
      "eaed4ddc29a94cbba683c9ddd8cb280c",
      "601ce9cbb8fe49a0b2595a011c527892",
      "11b18f3c181841d681a9bbee8853dfef",
      "968faeaa2e674141a87f1d1d0405fcf6",
      "f52721788f964b138beb5f355ba1afd3",
      "f9525a25b505415aace6a960ece04acb",
      "9e29e77aa8354e94964a543690dc8c7b",
      "a815e692f170470a94fe2e429bc65865",
      "6dc3186f87c24aa2bac799b2c754c8e0",
      "7f51ef69bbad423bb0936af1689d4a25",
      "d837d69f49b8491ea5db9bd1c7cde173",
      "3f6b8844702d47d6bae4d8d652f0b6ca",
      "abd8fee9e9a945c085442ccb019e995b",
      "8ac451bc75634326b596144d539189b8",
      "ccb0f67b1bbd4a30b818daba5e5e71c7",
      "c3519209b58249b88f0758f8e517a153",
      "4bc6fbf67bce453c9db4d96e22ee4d76"
     ]
    },
    "id": "CN8dWRxgatuG",
    "outputId": "fd0423c2-6b70-4c97-97aa-2cef7627c380"
   },
   "outputs": [],
   "source": [
    "# 다음 코드는 꼭 colab 에서 실행시키세요\n",
    "\n",
    "heart.profile_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adrmTXeG6Mg9"
   },
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "데이터프레임 `heart`에는 연속형 설명변수와 범주형 설명변수가 같이 포함되어 있다. 아래 코드에서 `info()` 메소드는 데이터프레임의 야에 대한 자료의 형식을 나타내는 것이다. 형식 `Dtype` 이 `object` 로 나타나는 열이 범주형 변수이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2Hg8OWTahvj",
    "outputId": "409e33c2-4262-41ea-dd7f-71292f1e1d44"
   },
   "outputs": [],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TlAY52j7GEm"
   },
   "source": [
    "설명변수가 범주형인 경우 기계학습 모형을 이용하기 위해서는 각 범주형 변수에 대한 가변수(dummy variable)을 만들어 주어야 한다. 가변수는 범주의 개수보다 하나 작은 개수의  연속형 변수들를 만들어 주는 것이다.\n",
    "\n",
    "예를 들어 변수 `RestingECG` 는 `Normal`, `LVS`, `ST`  세 가지 범주로 구성되어 있다면 두 개의 연속형 변수 `RestingECG_Normal`, `\tRestingECG_ST`를 만들어 다음과 같이 범주를 나타내는 것이다.\n",
    "\n",
    "\n",
    "| 원래변수 `RestingECG` 의 값 | `RestingECG_Normal` | `\tRestingECG_ST`|\n",
    "|:------:|:------:|:------:|\n",
    "|`Normal` |   1 |  0 |\n",
    "|`ST` | 0 | 1 |\n",
    "|`LVS` | 0 | 0 |\n",
    "\n",
    "먼저 메소드 `select_dtypes(include=object).columns`를 이용하여 범주형 변수로 구성된 모든 열의 이름을 `cat_col_names`에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnl96gXJ-Fmt",
    "outputId": "dfc7b8c8-2cef-472b-da4f-1ccd4472bd76"
   },
   "outputs": [],
   "source": [
    "# 범주형 변수로 구성된 모든 열의 이름 추출\n",
    "cat_col_names = heart.select_dtypes(include=object).columns\n",
    "cat_col_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g5aaSVd-HMj"
   },
   "source": [
    "다음으로 메소드 `get_dummies(heart, cat_col_names, drop_first=True)` 를 사용하여 가변수를 생성하자. 가변수를 포함한 데이터프레임은 `heart2` 에 저장한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "oUJeCugBc6b4",
    "outputId": "61d48c0e-d6bc-43be-893a-55bb64d29467"
   },
   "outputs": [],
   "source": [
    "# 범주형변수에 대한 가변수를 생성하고 새로운 데이터 프레임에 저장한다. \n",
    "heart2 = pd.get_dummies(heart, columns=cat_col_names, drop_first=True)  \n",
    "heart2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "AhDyGkNum_4w",
    "outputId": "d7ba375d-0050-4e61-d8db-c2453184ddae"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=heart2, x= \"MaxHR\", y= \"Cholesterol\", hue=\"HeartDisease\", palette=\"deep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXst08N7_2_4"
   },
   "source": [
    "이제 앞에서 언급한 것처럼 전체 데이터를  학습 데이터와 검증 데이터로 나눌 것이다.\n",
    "\n",
    "먼저 반응변수 `HeartDisease` 와 독립변수들을 나누어서 저장하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yLNKdPjAa9g"
   },
   "outputs": [],
   "source": [
    "# 독립변수들 \n",
    "X =  heart2.drop(columns='HeartDisease')\n",
    "# 표준화\n",
    "X = np.array(X.apply(standarize, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TnJpipSAYqm"
   },
   "outputs": [],
   "source": [
    "# 반응변수 \n",
    "y = heart['HeartDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyc-kuEIAh5p"
   },
   "source": [
    "이제 반응변수 행렬 `y` 와 독립변수 행렬 `X` 를 각각 학습데이터와 검증데이터로 나눈다.\n",
    "\n",
    "학습데이터와 검증데이터로 나눈 떄는 함수 `train_test_split()` 을 사용한다. `test_size` 는 0과 1 사이의 비율이며 검증 데이터가 전체 자료에서 차지하는 비율을 지정한다. 검증데이터는 원 자료에서 임의로 추출된다.\n",
    "\n",
    "아래 파이썬 코드는 `heart2` 데이처프레임에서 30% 의 자료를 검증 데이터로 추출하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RhAW9ptdOpg"
   },
   "outputs": [],
   "source": [
    "# 학습데이터와 검증데이터로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzQZJDVrCrkV",
    "outputId": "c51fc106-b98f-4768-ac72-d5a834d0043b"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l-edeRbB3cz"
   },
   "source": [
    "## 모형의 적합\n",
    "\n",
    "\n",
    "이제 학습 데이터를 이용하여 로지스틱 회귀 모형을 적합시켜 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KS78NNXXdPZG",
    "outputId": "cedac8a7-796e-4e9c-c473-7e74625ec203"
   },
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모형 정의\n",
    "heart2_logistic_model = LogisticRegression()\n",
    "\n",
    "# 모형적합\n",
    "heart2_logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN2TOZwhFKy1"
   },
   "source": [
    "로지스틱 회귀모형을 추정된 계수를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zwYb_CzFbo_",
    "outputId": "080b7b4b-e037-4f63-e346-728eb8844832"
   },
   "outputs": [],
   "source": [
    "# beta0\n",
    "b0 = heart2_logistic_model.intercept_[0]\n",
    "\n",
    "# beta1, beta2 \n",
    "heart2_logistic_model.coef_.T\n",
    "\n",
    "b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNZiAY5EFzPz",
    "outputId": "779fc5d2-f65c-4962-840f-90e98ba0d2f8"
   },
   "outputs": [],
   "source": [
    "heart2_logistic_model.coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW9InzeVF43A"
   },
   "source": [
    "## 예측의 정확성\n",
    "\n",
    "이제 마지막으로 검증 데이터에 적합된 모형을 사용하여 예측의 정확성를 구해보자. 예측의 정확성 비율은 함수 `accuracy_scrore(y_true, y_new)`를 이용하여 계산한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-hxOrg1S-eE",
    "outputId": "394ef7cb-d406-44cf-cac7-31ac0100dea6"
   },
   "outputs": [],
   "source": [
    "# 검증 데이터에 대한 예측값 생성 \n",
    "y_pred = heart2_logistic_model.predict(X_test)\n",
    "# 에측의 정확성 계산\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "5W0RobpfcJlt",
    "outputId": "dad47634-55e3-40bc-b75c-b170822f8749"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'y_true':y_test, 'y_pred': y_pred })\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpO1hBY_HMn_"
   },
   "source": [
    "참고로 검증자료가 없고 전체 자료를 학습 데이터로 이용하여 모형을 적합하고 동일한 학습데이터로 예측의 정확성을 계산해 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQe_YZoYIgga",
    "outputId": "08a8c79e-0497-48a3-caa6-4f6f845905ca"
   },
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모형 정의\n",
    "heart2_logistic_model_A = LogisticRegression()\n",
    "\n",
    "# 전체 데이터를 이용한 모형적합\n",
    "heart2_logistic_model_A.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3g5Ve2tInk4",
    "outputId": "7b3b9b32-099a-49be-84e9-94c5094864a9"
   },
   "outputs": [],
   "source": [
    "# 전체 데이터에 대한 예측값 생성 \n",
    "y_pred_A = heart2_logistic_model.predict(X)\n",
    "# 예측의 정확성 계산\n",
    "print('Accuracy: %.4f' % accuracy_score(y, y_pred_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMrAin20KGQM"
   },
   "source": [
    "위의 결과에서 본 것처럼 독립적인 검증 데이터로 구한 예측의 정확성이 동일한 학습데이터로 부터 구한 예측의 정확성보다 일반적으로  작게 나타난다. \n",
    "\n",
    "다시 강조하면 독립적인 검증 데이터로 구한 예측의 정확성이 더 정확한 측도이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAnBsv5SMMZc"
   },
   "source": [
    "## 기계학습 방법의 평가\n",
    "\n",
    "이제 앞 절에서 다룬 4개의 기계학습 모형들을 이용하여 심장병 예측에 대한 예측의 정확도를 비교해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIolvjkqKqBH",
    "outputId": "3956704f-23d7-4967-c3ae-705faf8a6b42"
   },
   "outputs": [],
   "source": [
    "# 기계학습 모형의 정의\n",
    "model_logistic = LogisticRegression()\n",
    "model_tree = DecisionTreeClassifier(max_depth=3)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "model_svm = SVC(gamma=0.1, kernel=\"rbf\", probability=True)\n",
    "\n",
    "# 모형의 적합\n",
    "model_logistic.fit(X_train, y_train)\n",
    "model_tree.fit(X_train, y_train)\n",
    "model_knn.fit(X_train, y_train)\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "5Y5Tzj-TKqGD",
    "outputId": "7c3f4634-da59-451d-971d-1e07f8cb0c4f"
   },
   "outputs": [],
   "source": [
    "df_accuracy = pd.DataFrame({'model': [\"Logisitc\",\"Decision Tree\", \"KNN\", \"Kernel SVM\"], 'accuracy': np.zeros(4)})\n",
    "\n",
    "for i, clf in enumerate([ model_logistic, model_tree, model_knn, model_svm]):\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    df_accuracy.iloc[i,1] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "df_accuracy    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH5ivScsMtYf"
   },
   "source": [
    "위의 결과를 보면 서포트 벡터 머신이 가장 좋은 예측의 정확도를 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9DItm3gaHou"
   },
   "source": [
    "## 정리\n",
    "\n",
    "분류에서 예측을 하는 절차를 정리하면 다음과 같다.\n",
    "\n",
    "1. 데이터의 전처리\n",
    "  + 반응변수를 1과 0으로 코딩\n",
    "  + 연속형 설명변수를 표준화\n",
    "  + 범주형 설병변수에 대한 가변수 생성 \n",
    "  + 데이터를 학습데이터와 검증데이터로 분리 (`X_train, X_test, y_train, y_test`) \n",
    "2. 예측 모형의 정의\n",
    "  + 예:\n",
    "```\n",
    "my_model = LogisticRegression()\n",
    "```\n",
    "\n",
    "3. 학습 데이터를 이용한 모형의 적합\n",
    "  + 예:\n",
    "```\n",
    "my_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "4. 검증 데이터를 이용한 모형의 평가 \n",
    "  + 예측의 정확도 계산\n",
    "  + 예:\n",
    "```\n",
    "y_pred = my_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ksr2HGA3bVbS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
